{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank,brown, movie_reviews, wordnet\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.data import find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS TO YOUR INPUT FILE PATH\n",
    "# SHOULD BE A CVS FILE FROM PREVIOUS STEP\\n ,\n",
    "input_fname = 'data/amr-bank-struct-v1.6-training.csv'\n",
    "\n",
    "# CHANGE THIS TO YOUR OUTPUT FILE PATH\\n ,\n",
    "output_fname = 'train' \n",
    "\n",
    "# if you want S * 5 * 300\n",
    "# Change this to five\n",
    "# if you want padded input\n",
    "# change this to pad\n",
    "mode = 'pad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_fname) \n",
    "# df = pd.read_csv('data/1.csv') \n",
    "nor_word = list(df['normalized_words']) \n",
    "isfocus = list(df['isfocus']) \n",
    "index = list(df['index']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(): \n",
    "    first = True \n",
    "    max_length = 0 \n",
    "    for i in range(len(index)): \n",
    "        if index[i]== 0 or i+1 == len(index): \n",
    "            if first: \n",
    "                first = False \n",
    "            else: \n",
    "                if len(tmp_nword)> max_length: \n",
    "                    max_length = len(tmp_nword) \n",
    "                wv = [] \n",
    "                sent.append(tmp_nword) \n",
    "                for j in tmp_nword: \n",
    "                    if j in model: \n",
    "                        wv.append(model[j]) \n",
    "                    else: \n",
    "                        wv.append(np.zeros(300)) \n",
    "                assert(len(wv) == index[i-1]+1) \n",
    "                n.append(np.asarray(wv)) \n",
    "                assert(len(tmp_f) == len(wv)) \n",
    "                f.append(np.asarray(tmp_f)) \n",
    "            tmp_nword = [] \n",
    "            tmp_f = [] \n",
    "            \n",
    "        tmp_nword.append(nor_word[i]) \n",
    "        tmp_f.append(isfocus[i]) \n",
    "    return max_length \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(n,f): \n",
    "    for i in range(len(n)): \n",
    "        if len(n[i]) < max_length: \n",
    "            pad_num = max_length - len(n[i]) \n",
    "            n[i] = np.concatenate((n[i],np.empty((pad_num,300))),axis=0) \n",
    "            \n",
    "    # 0 for no-word \n",
    "    # 1 for non-focus \n",
    "    # 2 for focus \n",
    "    for i in range(len(f)): \n",
    "        for j in range(len(f[i])): \n",
    "            if f[i][j] == 1: \n",
    "                f[i][j] = 2 \n",
    "\n",
    "            if f[i][j] == 0: \n",
    "                f[i][j] = 1 \n",
    "\n",
    "    for i in range(len(f)): \n",
    "        if len(f[i]) < max_length: \n",
    "            pad_num = max_length - len(f[i]) \n",
    "            f[i] = np.concatenate((f[i],np.zeros(pad_num)),axis=0)  \n",
    "            \n",
    "    return n,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_5(n,f):\n",
    "    n5 = []\n",
    "    f5 = []\n",
    "    for i in range(len(n)):\n",
    "        if len(n[i]) < 5: \n",
    "            tmp = n[i] \n",
    "            tmp = np.concatenate((tmp,np.zeros((5-len(n[i]),300)))) \n",
    "            n5.append(np.array(tmp)) \n",
    "\n",
    "            tmpf = f[i] \n",
    "            tmpf = np.concatenate((tmpf,np.zeros(5-len(f[i])))) \n",
    "            f5.append(np.array(tmpf)) \n",
    "\n",
    "        for j in range(len(n[i])-4): \n",
    "            n5.append(n[i][j:j+5]) \n",
    "            f5.append(f[i][j:j+5]) \n",
    "\n",
    "    return n5,f5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [] \n",
    "f = [] \n",
    "sent = [] \n",
    "max_length = prepro() \n",
    "assert(len(n) == len(f)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'pad':\n",
    "    nn,ff = padding(n,f)\n",
    "else:\n",
    "    nn,ff = div_f(n,f)\n",
    "\n",
    "nn = np.asarray(nn)\n",
    "ff = np.asarray(ff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'five':\n",
    "    np.save('word_embedding_divby5_'+output_fname,nn)\n",
    "    np.save('isfocus_divby5_'+output_fname,ff)\n",
    "else:\n",
    "    np.save('word_embedding_'+ output_fname,nn)\n",
    "    np.save('isfocus_'+ output_fname,ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1274, 101, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1274, 101)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
