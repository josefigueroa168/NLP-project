{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from gensim.models import Word2Vec\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isfocus</th>\n",
       "      <th>focus</th>\n",
       "      <th>word</th>\n",
       "      <th>normalized_words</th>\n",
       "      <th>index</th>\n",
       "      <th>POS</th>\n",
       "      <th>-1POS</th>\n",
       "      <th>-2POS</th>\n",
       "      <th>+1POS</th>\n",
       "      <th>+2POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>chapter</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>CD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>chapter</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>CD</td>\n",
       "      <td>NN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>.</td>\n",
       "      <td>XXXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>chapter</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>CD</td>\n",
       "      <td>NN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>reveal</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>DT</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>reveal</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>DT</td>\n",
       "      <td>IN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isfocus    focus     word normalized_words  index POS -1POS -2POS +1POS  \\\n",
       "0        1  chapter  Chapter          chapter      0  NN  XXXX  XXXX    CD   \n",
       "1        0  chapter        7                7      1  CD    NN  XXXX     .   \n",
       "2        0  chapter        .                .      2   .    CD    NN  XXXX   \n",
       "3        0   reveal       On               on      0  IN  XXXX  XXXX    DT   \n",
       "4        0   reveal      the              the      1  DT    IN  XXXX    JJ   \n",
       "\n",
       "  +2POS  \n",
       "0     .  \n",
       "1  XXXX  \n",
       "2  XXXX  \n",
       "3    JJ  \n",
       "4    NN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('data/amr-bank-struct-v1.6-training.csv', encoding = 'utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>normalized_words</th>\n",
       "      <th>isfocus</th>\n",
       "      <th>index</th>\n",
       "      <th>POS</th>\n",
       "      <th>-1POS</th>\n",
       "      <th>-2POS</th>\n",
       "      <th>+1POS</th>\n",
       "      <th>+2POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>CD</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CD</td>\n",
       "      <td>NN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>.</td>\n",
       "      <td>XXXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>CD</td>\n",
       "      <td>NN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>DT</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DT</td>\n",
       "      <td>IN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word normalized_words  isfocus  index POS -1POS -2POS +1POS +2POS\n",
       "0  Chapter          chapter        1      0  NN  XXXX  XXXX    CD     .\n",
       "1        7                7        0      1  CD    NN  XXXX     .  XXXX\n",
       "2        .                .        0      2   .    CD    NN  XXXX  XXXX\n",
       "3       On               on        0      0  IN  XXXX  XXXX    DT    JJ\n",
       "4      the              the        0      1  DT    IN  XXXX    JJ    NN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.loc[:,['word','normalized_words','isfocus','index','POS','-1POS','-2POS','+1POS','+2POS']]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['normalized_words'] = x['normalized_words']+' '+x['index'].astype(str)+' '+x['POS']+' '+x['-1POS']+' '+x['-1POS']+' '+x['-2POS']+' '+x['+1POS']+' '+x['+2POS']\n",
    "x['normalized_words'] = x['normalized_words']+' '+x['index'].astype(str)+' '+x['POS']+' '+x['-1POS']+' '+x['-1POS']+' '+x['-2POS']+' '+x['+1POS']+' '+x['+2POS']\n",
    "x = x.iloc[0:10000,0:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = x[df.isfocus == 0]\n",
    "df_1 = x[df.isfocus == 1]\n",
    "\n",
    "df_majority_downsampled = resample(df_0, \n",
    "                                 replace=False,\n",
    "                                 n_samples=df_1.size,     \n",
    "                                 random_state=123) \n",
    "\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_1])\n",
    "\n",
    "X = df_downsampled['normalized_words'].values\n",
    "y = df_downsampled['isfocus'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5,\n",
    "                                                    random_state = 1234,stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer_obj = Tokenizer()\n",
    "total_words = X_train +X_test\n",
    "tokenizer_obj.fit_on_texts(total_words)\n",
    "\n",
    "max_length = max([len(s.split()) for s in total_words])\n",
    "\n",
    "vocab_size =len(tokenizer_obj.word_index)+1\n",
    "\n",
    "X_train_tokens = tokenizer_obj.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer_obj.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen = max_length, padding = 'post')\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen = max_length, padding ='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_67 (Embedding)     (None, 15, 100)           83900     \n",
      "_________________________________________________________________\n",
      "gru_64 (GRU)                 (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 96,701\n",
      "Trainable params: 96,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding,GRU\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "EMBEDDING_DIM =100\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length = max_length))\n",
    "model.add(GRU(units=32, dropout =0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 813 samples, validate on 813 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 0.6803 - acc: 0.6125 - val_loss: 0.6577 - val_acc: 0.6667\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6487 - acc: 0.6667 - val_loss: 0.6386 - val_acc: 0.6667\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6379 - acc: 0.6667 - val_loss: 0.6371 - val_acc: 0.6667\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6383 - acc: 0.6667 - val_loss: 0.6372 - val_acc: 0.6667\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6406 - acc: 0.6667 - val_loss: 0.6364 - val_acc: 0.6667\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6375 - acc: 0.6667 - val_loss: 0.6363 - val_acc: 0.6667\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6390 - acc: 0.6667 - val_loss: 0.6363 - val_acc: 0.6667\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6389 - acc: 0.6667 - val_loss: 0.6362 - val_acc: 0.6667\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6386 - acc: 0.6667 - val_loss: 0.6362 - val_acc: 0.6667\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6349 - acc: 0.6667 - val_loss: 0.6362 - val_acc: 0.6667\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6382 - acc: 0.6667 - val_loss: 0.6361 - val_acc: 0.6667\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6371 - acc: 0.6667 - val_loss: 0.6360 - val_acc: 0.6667\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6372 - acc: 0.6667 - val_loss: 0.6365 - val_acc: 0.6667\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6344 - acc: 0.6667 - val_loss: 0.6358 - val_acc: 0.6667\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6365 - acc: 0.6667 - val_loss: 0.6356 - val_acc: 0.6667\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6358 - acc: 0.6667 - val_loss: 0.6352 - val_acc: 0.6667\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6327 - acc: 0.6667 - val_loss: 0.6351 - val_acc: 0.6667\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6374 - acc: 0.6667 - val_loss: 0.6343 - val_acc: 0.6667\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6323 - acc: 0.6667 - val_loss: 0.6333 - val_acc: 0.6667\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6304 - acc: 0.6667 - val_loss: 0.6312 - val_acc: 0.6667\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6264 - acc: 0.6667 - val_loss: 0.6272 - val_acc: 0.6667\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6163 - acc: 0.6679 - val_loss: 0.6180 - val_acc: 0.6667\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.5969 - acc: 0.6740 - val_loss: 0.5969 - val_acc: 0.6667\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.5682 - acc: 0.6863 - val_loss: 0.5553 - val_acc: 0.7036\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.5171 - acc: 0.7294 - val_loss: 0.5058 - val_acc: 0.7823\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.4534 - acc: 0.7897 - val_loss: 0.4625 - val_acc: 0.8106\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.3868 - acc: 0.8290 - val_loss: 0.4324 - val_acc: 0.8303\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.3204 - acc: 0.8684 - val_loss: 0.4441 - val_acc: 0.8303\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.2927 - acc: 0.8672 - val_loss: 0.4585 - val_acc: 0.8364\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.2729 - acc: 0.8881 - val_loss: 0.4571 - val_acc: 0.8561\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2233 - acc: 0.9200 - val_loss: 0.4795 - val_acc: 0.8315\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.1877 - acc: 0.9336 - val_loss: 0.5270 - val_acc: 0.8413\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.1586 - acc: 0.9446 - val_loss: 0.5877 - val_acc: 0.8487\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.1392 - acc: 0.9619 - val_loss: 0.6287 - val_acc: 0.8450\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.1621 - acc: 0.9520 - val_loss: 0.6393 - val_acc: 0.8450\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.1499 - acc: 0.9594 - val_loss: 0.6458 - val_acc: 0.8290\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.1536 - acc: 0.9569 - val_loss: 0.6413 - val_acc: 0.8339\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.1285 - acc: 0.9643 - val_loss: 0.6435 - val_acc: 0.8426\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.1479 - acc: 0.9569 - val_loss: 0.6451 - val_acc: 0.8315\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.1379 - acc: 0.9631 - val_loss: 0.6463 - val_acc: 0.8327\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.1338 - acc: 0.9656 - val_loss: 0.6459 - val_acc: 0.8327\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.1486 - acc: 0.9557 - val_loss: 0.6504 - val_acc: 0.8290\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.1362 - acc: 0.9643 - val_loss: 0.6465 - val_acc: 0.8266\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.1244 - acc: 0.9631 - val_loss: 0.6514 - val_acc: 0.8278\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.1330 - acc: 0.9545 - val_loss: 0.6674 - val_acc: 0.8266\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.1211 - acc: 0.9643 - val_loss: 0.6875 - val_acc: 0.8278\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.1211 - acc: 0.9631 - val_loss: 0.6994 - val_acc: 0.8278\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.1100 - acc: 0.9692 - val_loss: 0.7114 - val_acc: 0.8352\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.1055 - acc: 0.9729 - val_loss: 0.7282 - val_acc: 0.8339\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1381 - acc: 0.9643 - val_loss: 0.7283 - val_acc: 0.8303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a864a7588>"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train, batch_size=128, epochs =50, validation_data= (X_test_pad, \n",
    "                                                                            y_test),verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x = X_test_pad)\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i][0] >= 0.9:\n",
    "        y_pred[i][0] = 1\n",
    "    else:\n",
    "        y_pred[i][0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.7226890756302521\n",
      "[[509  33]\n",
      " [ 99 172]]\n",
      "0.8376383763837638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print ('f1_score: ',f1_score(y_true=y_test, y_pred=y_pred))\n",
    "cm_svm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print (cm_svm)\n",
    "def accuracy(cm):\n",
    "    return np.trace(cm)/np.sum(cm)\n",
    "print (accuracy(cm_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00641237],\n",
       "       [0.0059375 ],\n",
       "       [0.00600799],\n",
       "       [0.0052671 ],\n",
       "       [0.00553304],\n",
       "       [0.00549879]], dtype=float32)"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "# test_sample_1 = 'say 9 VBD NN NN DT , ``'\n",
    "# test_sample_2 = 'prince 9 NN JJ JJ DT , CC'\n",
    "# test_sample_3 = 'reveal 26 VBN VBD VBD NN TO PRP'\n",
    "# test_sample_4 = 'chapter 0 NN XXXX XXXX XXXX CD .'\n",
    "# test_sample_5 = 'little 21 JJ DT DT IN NN POS'\n",
    "# test_sample_6 = 'i 1 PRP `` XXXX VBP RB'\n",
    "\n",
    "test_sample_1 = 'see 6 VBN VBN VBN RB IN DT'\n",
    "test_sample_2 = 'present 8 VBN VBD VBD NN PRP TO'\n",
    "test_sample_3 = 'account 24 NN IN IN VBZ IN DT'\n",
    "test_sample_4 = 'he 1 PRP CC CC XXXX VBD IN'\n",
    "test_sample_5 = 'in 3 IN VBD VBD PRP JJ NN'\n",
    "test_sample_6 = 'of 23 IN NN NN IN NN ,'\n",
    "test_samples=[test_sample_1,test_sample_2,test_sample_3,test_sample_4,test_sample_5,test_sample_6]\n",
    "test_samples_tokens = tokenizer_obj.texts_to_sequences (test_samples)\n",
    "test_samples_tokens_pad = pad_sequences(test_samples_tokens, maxlen=max_length)\n",
    "\n",
    "model.predict(x=test_samples_tokens_pad)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-299-16b4a43ecc59>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-299-16b4a43ecc59>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    0,contrast,in,in,3,IN,VBD,PRP,JJ,NN\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
