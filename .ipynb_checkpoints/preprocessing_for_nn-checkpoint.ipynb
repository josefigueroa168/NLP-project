{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank,brown, movie_reviews, wordnet\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.data import find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = Word2Vec(treebank.sents())\n",
    "# b = Word2Vec(brown.sents())\n",
    "# mr = Word2Vec(movie_reviews.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS TO YOUR INPUT FILE PATH\n",
    "# SHOULD BE A CVS FILE FROM PREVIOUS STEP\n",
    "input_fname = 'data/amr-bank-struct-v1.6-training.csv'\n",
    "\n",
    "# CHANGE THIS TO YOUR OUTPUT FILE PATH\n",
    "output_fname = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_fname)\n",
    "# df = pd.read_csv('data/1.csv')\n",
    "nor_word = list(df['normalized_words'])\n",
    "isfocus = list(df['isfocus'])\n",
    "index = list(df['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro():\n",
    "    first = True\n",
    "    max_length = 0\n",
    "    for i in range(len(index)):\n",
    "        if index[i]== 0 or i+1 == len(index):\n",
    "            if first:\n",
    "                first = False\n",
    "            else:\n",
    "                if len(tmp_nword)> max_length:\n",
    "                    max_length = len(tmp_nword)\n",
    "                wv = []\n",
    "                sent.append(tmp_nword)\n",
    "                for j in tmp_nword:\n",
    "                    if j in model:\n",
    "                        wv.append(model[j])\n",
    "                    else:\n",
    "                        wv.append(np.zeros(300))\n",
    "                assert(len(wv) == index[i-1]+1)\n",
    "                n.append(np.asarray(wv))\n",
    "                assert(len(tmp_f) == len(wv))\n",
    "                f.append(np.asarray(tmp_f))\n",
    "            tmp_nword = []\n",
    "            tmp_f = []\n",
    "        tmp_nword.append(nor_word[i])\n",
    "        tmp_f.append(isfocus[i])\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding():\n",
    "    for i in range(len(n)):\n",
    "        if len(n[i]) < max_length:\n",
    "            pad_num = max_length - len(n[i])\n",
    "            n[i] = np.concatenate((n[i],np.empty((pad_num,300))),axis=0)\n",
    "    # 0 for no-word\n",
    "    # 1 for non-focus\n",
    "    # 2 for focus\n",
    "    for i in range(len(f)):\n",
    "        for j in range(len(f[i])):\n",
    "            if f[i][j] == 1:\n",
    "                f[i][j] = 2\n",
    "\n",
    "            if f[i][j] == 0:\n",
    "                f[i][j] = 1\n",
    "\n",
    "    for i in range(len(f)):\n",
    "        if len(f[i]) < max_length:\n",
    "            pad_num = max_length - len(f[i])\n",
    "            f[i] = np.concatenate((f[i],np.zeros(pad_num)),axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_5(n,f):\n",
    "    n5 = []\n",
    "    f5 = []\n",
    "    for i in range(len(n)):\n",
    "        if len(n[i]) < 5:\n",
    "            tmp = n[i]\n",
    "            tmp = np.concatenate((tmp,np.zeros((5-len(n[i]),300))))\n",
    "            n5.append(np.array(tmp))\n",
    "            \n",
    "            tmpf = f[i]\n",
    "            tmpf = np.concatenate((tmpf,np.zeros(5-len(f[i]))))\n",
    "            f5.append(np.array(tmpf))\n",
    "            \n",
    "        for j in range(len(n[i])-4):\n",
    "            n5.append(n[i][j:j+5])\n",
    "            f5.append(f[i][j:j+5])\n",
    "    return n5,f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = []\n",
    "f = []\n",
    "sent = []\n",
    "max_length = prepro()\n",
    "assert(len(n) == len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n5,f5 = div_5(n,f)\n",
    "n5 = np.asarray(n5)\n",
    "f5 = np.asarray(f5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5449714441638207\n",
      "0.26354386825551046\n",
      "nan\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(n5[0].shape[0]):\n",
    "    print(np.sum(n5[0][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11917, 5, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11917, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('word_embedding_divby5_'+output_fname,n5)\n",
    "np.save('isfocus_divby5_'+output_fname,f5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.asarray(n)\n",
    "f = np.asarray(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1274,)\n",
      "(1274,)\n"
     ]
    }
   ],
   "source": [
    "print (n.shape)\n",
    "print (f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('word_embedding_'+ output_fname,n)\n",
    "np.save('isfocus_'+ output_fname,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('word_embedding_'+ output_fname+'.npy')\n",
    "y = np.load('isfocus_'+ output_fname+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(x) == len(n))\n",
    "for i in range(len(x)):\n",
    "    assert(len(x[i]) == len(n[i]))\n",
    "    assert(x[i].all() == n[i].all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(y) == len(f))\n",
    "for i in range(len(y)):\n",
    "    assert(y[i].all() == f[i].all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
